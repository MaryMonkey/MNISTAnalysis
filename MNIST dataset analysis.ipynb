{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Press shift+enter to run the codes in the cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.ndimage\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data and transform them into workable numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathX = \"MNIST_Xtrain.csv\"\n",
    "pathy = \"MNIST_ytrain.csv\"\n",
    "pathXreal = 'MNIST_Xtest.csv'\n",
    "#df_X = pd.read_csv(pathX, header = None).transpose()\n",
    "df_y = pd.read_csv(pathy, header = None)\n",
    "df_X = pd.read_csv(pathX, header = None)\n",
    "df_Xreal = pd.read_csv(pathXreal, header = None)\n",
    "\n",
    "X = df_X.values\n",
    "y = df_y.values.flatten() # flatten y to be row vector\n",
    "# I call the test values as real values since I need to use 'test' in train-test split, X_test=Xreal\n",
    "Xreal = df_Xreal.values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1. Data augmentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the data preprocessing stage, where I used only data augmentation, since normalization is already done, and feature selection gets rid off the pixel-grids. (The result with feature selection turns out to be 94% roughly, which is not bad but it is not better than non-feature selection stage which is this one I have currently.) So I decide to not to have feature selection stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Augmentation class consists of 4 methods for augmenting the original dataset: (1) rotation of the original dataset by 10 degrees clock-wise, (2) 10 degrees counter-clock wise, (3) translation to the right by 1 pixel, (4) and a combination of rotate10cw and translation. This will result in an augmented version of 300,000 data from the original 60,000 training dataset. The purpose is to train the learner to have it see different characteristics or styles of the digits so that it has better performance on the unseen dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentation:\n",
    "    \n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "        self.R10cw = np.concatenate((self.X, self.rotate10cw(self.X)), axis=0)\n",
    "        self.R10cwT = np.concatenate((self.R10cw, self.translation(self.X)), axis=0)\n",
    "        self.R10cwTR10ccw = np.concatenate((self.R10cwT, self.rotate10ccw(self.X)), axis=0)\n",
    "        self.R10cwTR10ccwANDRT = np.concatenate((self.R10cwTR10ccw, \n",
    "                                                 self.rotate10cw(self.translation(self.X))), axis=0)\n",
    "    \n",
    "    # rotate image 10 degrees clock-wise\n",
    "    def rotate10cw(self, X):\n",
    "        # create empty array for storing the rotation by 10-cw degrees\n",
    "        X_rot10cw = np.empty([self.X.shape[0], self.X.shape[1]]) \n",
    "        \n",
    "        for i,x in enumerate(self.X):\n",
    "            x_rot10cw = scipy.ndimage.interpolation.rotate(np.transpose(np.reshape(x,(28,28))), \n",
    "                                                         -10, axes=(1, 0), reshape=False)\n",
    "            x_rot10cw = np.transpose(x_rot10cw) #make column go first\n",
    "            X_rot10cw[i] = np.reshape(x_rot10cw.flatten(),(1,-1))\n",
    "        \n",
    "        return X_rot10cw \n",
    "    \n",
    "    # rotate the image 10 degrees ccw (counter-clock wise)\n",
    "    def rotate10ccw(self, X):\n",
    "        # create empty array for storing rotation by 10 degrees-ccw image\n",
    "        X_rot10ccw = np.empty([self.X.shape[0], self.X.shape[1]])\n",
    "        \n",
    "        for i,x in enumerate(self.X):\n",
    "            x_rot10ccw = scipy.ndimage.interpolation.rotate(np.transpose(np.reshape(x,(28,28))), \n",
    "                                                         10, axes=(1, 0), reshape=False)\n",
    "            x_rot10ccw = np.transpose(x_rot10ccw)\n",
    "            X_rot10ccw[i] = np.reshape(x_rot10ccw.flatten(),(1,-1))\n",
    "        \n",
    "        return X_rot10ccw\n",
    "        \n",
    "    # translate the image to the right by 1 pixel \n",
    "    def translation(self, X):\n",
    "        # create an empty array for storing the shift-right-by-1-pixel image\n",
    "        X_shift = np.empty([self.X.shape[0], self.X.shape[1]])\n",
    "        \n",
    "        for i,x in enumerate(self.X):\n",
    "            x_shift=scipy.ndimage.interpolation.shift(np.transpose(np.reshape(x,(28,28))), 1.)\n",
    "            x_shift = np.transpose(x_shift)\n",
    "            X_shift[i] = np.reshape(x_shift.flatten(),(1,-1))\n",
    "        \n",
    "        return X_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object of the Augmentation class and call it X_transform\n",
    "X_transform = Augmentation(X)\n",
    "\n",
    "#print(X_transform.R10cwTR10ccwANDRT.shape)\n",
    "\n",
    "# increase the dimension of y as well\n",
    "y_R = np.concatenate((y, y), axis=0)\n",
    "y_RT = np.concatenate((y_R,y), axis=0)\n",
    "y_RTR = np.concatenate((y_RT,y), axis=0)\n",
    "y_RTRrt = np.concatenate((y_RTR, y), axis=0)\n",
    "\n",
    "#print(y_RTRrt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2. Model Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Please bare with this CrossValidate class, it will take approximately 4.5 days...*** Thank you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1). The classifier used is Support Vector Machine which maximizes the Lagrangian dual objective function:\n",
    "\n",
    "\\begin{equation*}\n",
    "L_D = \\sum_{i=1}^N \\alpha_i - \\frac{1}{2} \\sum_{i=1}^N \\sum_{i'=1}^N \\alpha_i \\alpha_{i'} y_i y_{i'} \\langle h(x_i),h(x_{i'}) \\rangle\n",
    "\\end{equation*}\n",
    "\n",
    "subjected to $C \\ge \\alpha_i \\ge 0$ and $\\sum_{i=1}^N \\alpha_i y_i =0$, and I applied some transformation $h(x)$ to the input vector space, in which I used the Radial Basis as the kernel functions:\n",
    "\n",
    "\\begin{equation*}\n",
    "K(x,x') = \\langle h(x), h(x') \\rangle = e^{(-\\gamma \\|x-x' \\|^2)}\n",
    "\\end{equation*}\n",
    "\n",
    "between two sample vectors $x$ and $x'$. The Kernal function does not depend on the actual transformation of $h(x)$, it only depends on the inner product between $h(x)$ and $h(x')$ for any $x$, $x'$ $\\in$ $X_{train}$. (I also tried ploy kernel with degree 2 and linear kernel and I tested all of them, rbf gives the highest score)\n",
    "\n",
    "2). 5-fold cross validation accompanied with a parameter grid-search algorithm, where the hyperparamters need to be determined are the penalization $C$ and the rbf parameter $\\gamma$. A grid-search is run through all the possible combinations for $C \\in$ [10,11,12,13] and $\\gamma \\in$ [0.01, 0.015] on a 5-fold cross validation scheme and the best $C-\\gamma$ pair, i.e. the ones that gives the highest CV accuracy is returned. And this $C-\\gamma$ pair is used on the entire X  dataset to obtain a final classifier to predict the labels for Xreal, the test dataset. I intially tried a coarse grid-search with $C$ = [10, 20, 30], and $C$=10 gave the highest accuracy and then now, I am doing a finer grid-search with $C$=[10,11,12,13] with $\\gamma$ unchanged. I also tried with other $\\gamma$ values as well, but it turns out that any value in between 0.01 and 0.03 works better among others, so I just picked two values 0.01 and 0.015 for the grid-search algorithm so that it takes relatively less time to run, since the algorithm needs to run 8 $C-\\gamma$ pairs and 5 times for each of them. (note: if you want to see some scratch work I have done, please check out the other_parallels.folder in which I attached some representive scratches among all the other values I tried)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidate:\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        C_options = [10, 11, 12, 13]\n",
    "        gamma_options = [0.01, 0.015]\n",
    "        print('selecting the parameters using 5-fold CV...')\n",
    "        print('please wait..')\n",
    "        self.candidate, cv_score = self.model_selection(self.X, self.y, C_options, gamma_options, 5)\n",
    "        \n",
    "        print('C-gamma pair on coarse grid-search: ' + str(self.candidate))\n",
    "        print('average accuracy of the CV: ' + str(cv_score))\n",
    "    \n",
    "    # paramter tuning\n",
    "    def model_selection(self, X, y, C_options, gamma_options, nfolds):\n",
    "        parameters = {'C': C_options, 'gamma' : gamma_options}\n",
    "        grid_search = GridSearchCV(SVC(kernel='rbf', random_state=0), parameters, cv=nfolds)\n",
    "        grid_search.fit(X, y)\n",
    "        candidate = grid_search.best_params_\n",
    "        cv_score = grid_search.best_score_\n",
    "        \n",
    "        return candidate, cv_score    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed the 300,000 training dataset to my CrossValidate class and return the $C-\\gamma$ candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = CrossValidate(X_transform.R10cwTR10ccwANDRT, y_RTRrt)\n",
    "\n",
    "result.candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once have the best $C$ and $\\gamma$ values, train on the entire X to get my final classifier and make predictions on Xreal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=result.candidate.get('C'), \n",
    "          gamma=result.candidate.get('gamma'), \n",
    "          kernel='rbf', random_state=0)\n",
    "\n",
    "svc.fit(X_transform.R10cwTR10ccwANDRT, y_RTRrt)\n",
    "\n",
    "# make predictions on X_test as provided in A2\n",
    "predictions = svc.predict(Xreal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a panada dataframe and save as .csv file. Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPred = pd.DataFrame({'Digit':predictions, 'ImageID':np.arange(1,Xreal.shape[0]+1)})\n",
    "#print(testPred)\n",
    "\n",
    "submission = pd.DataFrame({'ImageID': testPred['ImageID'], 'Digit':testPred['Digit']})\n",
    "filename = 'prediction.csv'\n",
    "submission.to_csv(filename,index=False)\n",
    "\n",
    "print('Saved file: ' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
